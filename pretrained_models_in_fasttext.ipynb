{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d82f256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = openml.datasets.get_dataset(42078)\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"dataframe\")\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=100_000, test_size=20_000, random_state=0, shuffle=True)\n",
    "str_cols = [col for col in X_train.columns if X[col].dtype == \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ddeaaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, log_loss, precision_score, recall_score\n",
    "\n",
    "def evaluate_clf(clf):\n",
    "  s = time.time()\n",
    "  clf.fit(X_train, y_train)\n",
    "  print(\"Model fit time:\", time.time() - s, \"seconds\")\n",
    "\n",
    "  y_pred = clf.predict(X_test)\n",
    "  y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "  print(\"###### Label Predictions #######\")\n",
    "  print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "  print(\"precision:\", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "  print(\"recall:\", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "  print(\"f1:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "  print(\"###### Label Probabilities #######\")\n",
    "  print(\"roc_auc:\", roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovr\"))\n",
    "  print(\"Log loss:\", log_loss(y_test, y_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60105721",
   "metadata": {},
   "source": [
    "# FastText without pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4493b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  146740\n",
      "Number of labels: 104\n",
      "Progress: 100.0% words/sec/thread:  988445 lr:  0.000000 avg.loss:  0.264490 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 9.409299850463867 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Label Predictions #######\n",
      "accuracy: 0.9471\n",
      "precision: 0.9184304975591595\n",
      "recall: 0.9115738264943514\n",
      "f1: 0.9133281387538676\n",
      "###### Label Probabilities #######\n",
      "roc_auc: 0.6607982366742533\n",
      "Log loss: 10.241884007488643\n"
     ]
    }
   ],
   "source": [
    "from gama.configuration.fasttextclassifier import FastTextClassifier\n",
    "import time\n",
    "\n",
    "clf = FastTextClassifier(epoch=15, lr=0.2)\n",
    "evaluate_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7605d0a3",
   "metadata": {},
   "source": [
    "# FastText with pretrained model, dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87545fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  146740\n",
      "Number of labels: 104\n",
      "Progress: 100.0% words/sec/thread:  997758 lr:  0.000000 avg.loss:  0.101807 ETA:   0h 0m 0s 39.8% words/sec/thread: 1006802 lr:  0.120379 avg.loss:  0.245574 ETA:   0h 0m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 106.84839177131653 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Label Predictions #######\n",
      "accuracy: 0.95085\n",
      "precision: 0.9282907799286956\n",
      "recall: 0.9216491119070563\n",
      "f1: 0.9236953304790346\n",
      "###### Label Probabilities #######\n",
      "roc_auc: 0.6532018107974695\n",
      "Log loss: 10.442995417574002\n"
     ]
    }
   ],
   "source": [
    "from gama.configuration.fasttextclassifier import FastTextClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, log_loss, precision_score, recall_score\n",
    "\n",
    "clf = FastTextClassifier(pretrainedVectors=\"100.vec\", pretrainedDim=100, epoch=15, lr=0.2)\n",
    "evaluate_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be2987",
   "metadata": {},
   "source": [
    "# FastText with pretrained model, dim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75971e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  146740\n",
      "Number of labels: 104\n",
      "Progress: 100.0% words/sec/thread: 1899770 lr:  0.000000 avg.loss:  0.123397 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 29.275720834732056 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Label Predictions #######\n",
      "accuracy: 0.9478\n",
      "precision: 0.9300823716726595\n",
      "recall: 0.9166128604129699\n",
      "f1: 0.9223670090719438\n",
      "###### Label Probabilities #######\n",
      "roc_auc: 0.646936175251893\n",
      "Log loss: 10.416794373251498\n"
     ]
    }
   ],
   "source": [
    "from gama.configuration.fasttextclassifier import FastTextClassifier\n",
    "\n",
    "clf = FastTextClassifier(pretrainedVectors=\"20.vec\", pretrainedDim=20, epoch=15, lr=0.2)\n",
    "evaluate_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a2a73",
   "metadata": {},
   "source": [
    "# FastText with pretrained model, dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e93c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  146740\n",
      "Number of labels: 104\n",
      "Progress: 100.0% words/sec/thread: 2483672 lr:  0.000000 avg.loss:  0.159481 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 18.906963109970093 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Label Predictions #######\n",
      "accuracy: 0.9425\n",
      "precision: 0.917707658423152\n",
      "recall: 0.9055881704508555\n",
      "f1: 0.9100104649580992\n",
      "###### Label Probabilities #######\n",
      "roc_auc: 0.6375738190918786\n",
      "Log loss: 10.369919593889739\n"
     ]
    }
   ],
   "source": [
    "from gama.configuration.fasttextclassifier import FastTextClassifier\n",
    "\n",
    "clf = FastTextClassifier(pretrainedVectors=\"10.vec\", pretrainedDim=10, epoch=15, lr=0.2)\n",
    "evaluate_clf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fabf5",
   "metadata": {},
   "source": [
    "# Results\n",
    "Using a pretrained model does barely improve the performance of FastTextClassifier on all the evaluated metrics, while greatly increasing the training time of the classifier due to the loading time of the pretrained models.\n",
    "\n",
    "Surprisingly, the usage of pretrained models even **lowers** scores that are calculated with class probabilities such as ROC AUC and log loss. We suspect that using pretrained models lowers the confidence of the classification model due to activations of word vectors from the pretrained model. \n",
    "\n",
    "# Conclusion\n",
    "We conclude that the usage of pretrained models **does not improve** the performance of the FastTextClassifier and is in some cases even detrimental to the performance. Not to mention that it also increases the training time significantly due to the loading time of the pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1475348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reduce the size of the pretrained model\n",
    "\n",
    "# import fasttext as ft\n",
    "# import fasttext.util\n",
    "\n",
    "# m = ft.load_model(\"cc.en.300.bin\")\n",
    "# m.get_dimension()\n",
    "# fasttext.util.reduce_model(m, 10)\n",
    "# m.save_model(\"cc.en.10.bin\")\n",
    "# m.get_dimension()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
